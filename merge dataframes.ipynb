{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ca4954d-d101-4c88-a5fb-289b2d234102",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sample_data=[(1,'Nikhil','CSE','AP',75),(2,'Jeeva','ENGLISH','AP',90),(3,'Uma','IT','AP',95)]\n",
    "columns=['ID','NAME','COURSE','STATE','PERCENTAGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d03994e8-43d3-44a5-a2ca-60c91fe58a1f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+-----+----------+\n| ID|  NAME| COURSE|STATE|PERCENTAGE|\n+---+------+-------+-----+----------+\n|  1|Nikhil|    CSE|   AP|        75|\n|  2| Jeeva|ENGLISH|   AP|        90|\n|  3|   Uma|     IT|   AP|        95|\n+---+------+-------+-----+----------+\n\n"
     ]
    }
   ],
   "source": [
    "df1=spark.createDataFrame(sample_data,columns)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79ec0a37-6342-4a16-aaec-f23fb46ca39b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sample_data2=[(5,'Nhil','CE','tn'),(6,'Jeva','EGLISH','up'),(7,'ma','eie','mp')]\n",
    "columns2=['ID','NAME','COURSE','STATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "856dbce9-fc9b-445e-8833-42f0d0fdfa18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+-----+\n| ID|NAME|COURSE|STATE|\n+---+----+------+-----+\n|  5|Nhil|    CE|   tn|\n|  6|Jeva|EGLISH|   up|\n|  7|  ma|   eie|   mp|\n+---+----+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df2=spark.createDataFrame(sample_data2,columns2)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb9b8814-ea67-46c9-89c5-92691f9c6474",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "now merge the above two dataframes.to merge these two dfs using union the number of columns in both dfs \n",
    "should be same\n",
    "we are adding another column in the second df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "494a2f73-24ab-4971-80cc-eb0f31f3788e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d8dff3b-387d-4534-ad24-9173968a7a5e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "lit function is used to add a constant value to all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b98e3140-dd10-4a28-aa1f-236eb748a4a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+-----+-----+\n| ID|NAME|COURSE|STATE|Marks|\n+---+----+------+-----+-----+\n|  5|Nhil|    CE|   tn| null|\n|  6|Jeva|EGLISH|   up| null|\n|  7|  ma|   eie|   mp| null|\n+---+----+------+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df2=df2.withColumn('Marks',lit('null'))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93d3420b-e266-452e-a785-636e5e942cf3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+-----+-----+\n| ID|  NAME| COURSE|STATE|Marks|\n+---+------+-------+-----+-----+\n|  5|  Nhil|     CE|   tn| null|\n|  6|  Jeva| EGLISH|   up| null|\n|  7|    ma|    eie|   mp| null|\n|  1|Nikhil|    CSE|   AP|   75|\n|  2| Jeeva|ENGLISH|   AP|   90|\n|  3|   Uma|     IT|   AP|   95|\n+---+------+-------+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "mergedf=df2.union(df1)\n",
    "mergedf.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "merge dataframes",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
